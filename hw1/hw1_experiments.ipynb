{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "martial-lounge",
   "metadata": {},
   "source": [
    "# Experimentation for nlp hw1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prerequisite-duncan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from preprocessing import *\n",
    "from speech import *\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from supervised_experiments import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-charger",
   "metadata": {},
   "source": [
    "## Supervised Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-groove",
   "metadata": {},
   "source": [
    "### Initial exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"speech.tar.gz\"\n",
    "data = Data(fname)\n",
    "preprocessors = [\n",
    "    CountVectorizer(),\n",
    "    CountVectorizer(stop_words=\"english\"),\n",
    "    CountVectorizer(stop_words=\"english\", tokenizer = LemmaTokenizer()),\n",
    "    CountVectorizer(stop_words=\"english\", tokenizer = LemmaTokenizer(), min_df = 2),\n",
    "    CountVectorizer(stop_words=\"english\", tokenizer = LemmaTokenizer(), min_df = 3),\n",
    "    CountVectorizer(stop_words=\"english\", tokenizer = LemmaTokenizer(), min_df = 4),\n",
    "    CountVectorizer(stop_words=\"english\", tokenizer = LemmaTokenizer(), min_df = 5),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-savings",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-debut",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-church",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "digital-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"speech.tar.gz\"\n",
    "\n",
    "feat_list = {\n",
    "    \"cv\":CountVectorizer(),\n",
    "    \"cv_lemma\": CountVectorizer(tokenizer = LemmaTokenizer()),\n",
    "    \"cv_stopw\": CountVectorizer(stop_words = \"english\"),\n",
    "    \"cv_lemma_stopw\":CountVectorizer(stop_words = \"english\", tokenizer = LemmaTokenizer()),\n",
    "    \"tfidf\":TfidfVectorizer(),\n",
    "    \"tfidf_lemma\": TfidfVectorizer(tokenizer = LemmaTokenizer()),\n",
    "    \"tfidf_stopw\": TfidfVectorizer(stop_words = \"english\"),\n",
    "    \"tfidf_lemma_stopw\":TfidfVectorizer(stop_words = \"english\", tokenizer = LemmaTokenizer()),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-knitting",
   "metadata": {},
   "source": [
    "### Feature ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "referenced-property",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| '-- train data'\n",
      "ic| member.name: 'train.tsv'\n",
      "ic| len(self.train_data): 4370\n",
      "ic| '-- val data'\n",
      "ic| member.name: 'dev.tsv'\n",
      "ic| len(self.val_data): 414\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "a1 = feature_ablation(fname, feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "suspected-sharp",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': 0.41304347826086957,\n",
       " 'cv_lemma': 0.43719806763285024,\n",
       " 'cv_stopw': 0.39855072463768115,\n",
       " 'cv_lemma_stopw': 0.4227053140096618,\n",
       " 'tfidf': 0.3743961352657005,\n",
       " 'tfidf_lemma': 0.38164251207729466,\n",
       " 'tfidf_stopw': 0.38164251207729466,\n",
       " 'tfidf_lemma_stopw': 0.3743961352657005}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-extra",
   "metadata": {},
   "source": [
    "### Dimensionality Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "downtown-timer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| '-- train data'\n",
      "ic| member.name: 'train.tsv'\n",
      "ic| len(self.train_data): 4370\n",
      "ic| '-- val data'\n",
      "ic| member.name: 'dev.tsv'\n",
      "ic| len(self.val_data): 414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4370, 7689)\n",
      "(414, 7689)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "data = Data(fname)\n",
    "data.preprocess(feat_list[\"cv_lemma\"], norm = True)\n",
    "print(data.train_x.shape)\n",
    "print(data.val_x.shape)\n",
    "# sys.exit(1)\n",
    "comp_list = [100,500, 1000, 1500, 2000, 2500, 3000, 4000, 5000]\n",
    "a2 = dimensionality_ablation(data, comp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "durable-guyana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{100: 0.2777777777777778,\n",
       " 500: 0.32608695652173914,\n",
       " 1000: 0.3357487922705314,\n",
       " 1500: 0.33816425120772947,\n",
       " 2000: 0.33816425120772947,\n",
       " 2500: 0.33816425120772947,\n",
       " 3000: 0.34299516908212563,\n",
       " 4000: 0.34057971014492755,\n",
       " 5000: 0.33816425120772947}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "integrated-cancer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| '-- train data'\n",
      "ic| member.name: 'train.tsv'\n",
      "ic| len(self.train_data): 4370\n",
      "ic| '-- val data'\n",
      "ic| member.name: 'dev.tsv'\n",
      "ic| len(self.val_data): 414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4370, 7689)\n",
      "(414, 7689)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "data = Data(fname)\n",
    "data.preprocess(feat_list[\"cv_lemma\"], norm = False)\n",
    "print(data.train_x.shape)\n",
    "print(data.val_x.shape)\n",
    "# sys.exit(1)\n",
    "comp_list = [100,500, 1000, 1500, 2000, 2500, 3000, 4000, 5000]\n",
    "a2_2 = dimensionality_ablation(data, comp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "retained-injury",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{100: 0.30434782608695654,\n",
       " 500: 0.37922705314009664,\n",
       " 1000: 0.4106280193236715,\n",
       " 1500: 0.4227053140096618,\n",
       " 2000: 0.43719806763285024,\n",
       " 2500: 0.4444444444444444,\n",
       " 3000: 0.4396135265700483,\n",
       " 4000: 0.4323671497584541,\n",
       " 5000: 0.43719806763285024}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-poison",
   "metadata": {},
   "source": [
    "### Model ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "promotional-mixer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| '-- train data'\n",
      "ic| member.name: 'train.tsv'\n",
      "ic| len(self.train_data): 4370\n",
      "ic| '-- val data'\n",
      "ic| member.name: 'dev.tsv'\n",
      "ic| len(self.val_data): 414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penalty='none' is not supported for the liblinear solver\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "data = Data(fname)\n",
    "data.preprocess(feat_list[\"cv_lemma\"], norm = False)\n",
    "svd = TruncatedSVD(n_components = 2500)\n",
    "data.train_x = svd.fit_transform(data.train_x)\n",
    "data.val_x = svd.transform(data.val_x)\n",
    "solvers = [\"lbfgs\", \"liblinear\", \"saga\", \"newton-cg\", \"sag\"]\n",
    "penalties = [\"l1\", \"l2\", 'none']\n",
    "a3 = solver_pen_ablation(data.train_x, data.train_y, data.val_x, data.val_y, solvers, penalties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "compressed-incentive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': {'lbfgs': '-',\n",
       "  'liblinear': 0.42995169082125606,\n",
       "  'saga': 0.43478260869565216,\n",
       "  'newton-cg': '-',\n",
       "  'sag': '-'},\n",
       " 'l2': {'lbfgs': 0.43478260869565216,\n",
       "  'liblinear': 0.4323671497584541,\n",
       "  'saga': 0.4420289855072464,\n",
       "  'newton-cg': 0.4420289855072464,\n",
       "  'sag': 0.4420289855072464},\n",
       " 'none': {'lbfgs': 0.4057971014492754,\n",
       "  'liblinear': '-',\n",
       "  'saga': 0.45652173913043476,\n",
       "  'newton-cg': 0.40096618357487923,\n",
       "  'sag': 0.4396135265700483}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-handy",
   "metadata": {},
   "source": [
    "## Unsupervised experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-battlefield",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-plymouth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-mercy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "checked-interim",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| 'Reading data'\n",
      "ic| '-- train data'\n",
      "ic| member.name: 'train.tsv'\n",
      "ic| len(self.train_data): 4370\n",
      "ic| '-- val data'\n",
      "ic| member.name: 'dev.tsv'\n",
      "ic| len(self.val_data): 414\n"
     ]
    }
   ],
   "source": [
    "ic(\"Reading data\")\n",
    "tarfname = \"speech.tar.gz\"\n",
    "speech = Data(tarfname)\n",
    "speech.preprocess()\n",
    "\n",
    "# train_extra_data = np.zeros((len(speech.train_data), 4))\n",
    "# val_extra_data = np.zeros((len(speech.val_data), 4))\n",
    "# lkp_dict = {\"-\":0,\n",
    "#             \".\":1,\n",
    "#            \",\":2,\n",
    "#            \";\":3,\n",
    "#            }\n",
    "\n",
    "# for i, sentence in tqdm(enumerate(speech.train_data)):\n",
    "#     for char in sentence.decode(\"utf-8\"):\n",
    "#         if char in lkp_dict:\n",
    "#             train_extra_data[i,lkp_dict[char]] += 1\n",
    "\n",
    "# print(\"Validation\")\n",
    "# for i, sentence in tqdm(enumerate(speech.val_data)):\n",
    "#     for char in sentence.decode(\"utf-8\"):\n",
    "#         if char in lkp_dict:\n",
    "#             val_extra_data[i,lkp_dict[char]] += 1\n",
    "            \n",
    "# print(speech.train_x.shape)\n",
    "\n",
    "# speech.train_x = scipy.sparse.hstack((speech.train_x, csr_matrix(train_extra_data)))\n",
    "# speech.val_x = scipy.sparse.hstack((speech.val_x, csr_matrix(val_extra_data)))\n",
    "# print(speech.train_x.shape)\n",
    "# print(speech.val_x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "satisfied-activity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4370, 7426)\n"
     ]
    }
   ],
   "source": [
    "print(speech.train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "basic-assurance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/showalte/.conda/envs/nlpenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "ic| 'Evaluating'\n",
      "ic| 'Training set'\n",
      "ic| '  Accuracy', acc: 0.9823798627002288\n",
      "ic| 'Validation set'\n",
      "ic| '  Accuracy', acc: 0.4227053140096618\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"HI\")\n",
    "import classify\n",
    "cls = classify.train_classifier(speech.train_x, speech.train_y)\n",
    "ic(\"Evaluating\")\n",
    "ic(\"Training set\")\n",
    "classify.evaluate(speech.train_x, speech.train_y, cls)\n",
    "ic(\"Validation set\")\n",
    "classify.evaluate(speech.val_x, speech.val_y, cls)\n",
    "\n",
    "# ic(\"Reading unlabeled data\")\n",
    "# unlabeled = read_unlabeled(tarfname, speech)\n",
    "# print(\"Writing pred file\")\n",
    "# write_pred_kaggle_file(unlabeled, cls, \"speech-pred.csv\", speech)\n",
    "\n",
    "# # # You can't run this since you do not have the true labels\n",
    "# # # ic \"Writing gold file\"\n",
    "# # # write_gold_kaggle_file(\"data/speech-unlabeled.tsv\", \"data/speech-gold.csv\")\n",
    "# # # w:rite_basic_kaggle_file(\"data/speech-unlabeled.tsv\", \"data/speech-basic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open(\"val_extra_data.pkl\", \"wb\") as file:\n",
    "    pkl.dump(val_extra_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-party",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(range(len(vocabulary_sorted)), [item[1] for item in vocabulary_sorted])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-mentor",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech.count_vect = CountVectorizer(stop_words = \"english\")#, tokenizer = LemmaTokenizer())\n",
    "matrix = speech.count_vect.fit_transform(speech.train_data)\n",
    "print(matrix.shape)\n",
    "freqs = zip(speech.count_vect.get_feature_names(), matrix.sum(axis=0).tolist()[0])    \n",
    "# sort from largest to smallest\n",
    "vocabulary_sorted = sorted(freqs, key=lambda x: -x[1])\n",
    "print(type(vocabulary_sorted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer as lemmatizer\n",
    "lemmatizer = lemmatizer()\n",
    "voc_l = [lemmatizer.lemmatize(i[0]) for i in vocabulary_sorted]\n",
    "print(len(list(set(voc_l))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(range(len(vocabulary_sorted)), [item[1] for item in vocabulary_sorted])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove_input_file = 'glove.txt'\n",
    "word2vec_output_file = 'word2vec.txt'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exposed-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lightweight-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "personal-argentina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv['dog'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-buying",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "nlpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

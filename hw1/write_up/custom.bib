@article{goldberg2014word2vec,
  title={word2vec Explained: deriving Mikolov et al.'s negative-sampling word-embedding method},
  author={Goldberg, Yoav and Levy, Omer},
  journal={arXiv preprint arXiv:1402.3722},
  year={2014}
}


@article{zhang2010understanding,
  title={Understanding bag-of-words model: a statistical framework},
  author={Zhang, Yin and Jin, Rong and Zhou, Zhi-Hua},
  journal={International Journal of Machine Learning and Cybernetics},
  volume={1},
  number={1-4},
  pages={43--52},
  year={2010},
  publisher={Springer}
}


@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}

@inproceedings{lilleberg2015support,
  title={Support vector machines and word2vec for text classification with semantic features},
  author={Lilleberg, Joseph and Zhu, Yun and Zhang, Yanqing},
  booktitle={2015 IEEE 14th International Conference on Cognitive Informatics \& Cognitive Computing (ICCI* CC)},
  pages={136--140},
  year={2015},
  organization={IEEE}
}

@article{mikolov2013distributed,
  title={Distributed representations of words and phrases and their compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  journal={arXiv preprint arXiv:1310.4546},
  year={2013}
}

@article{turney2010frequency,
  title={From frequency to meaning: Vector space models of semantics},
  author={Turney, Peter D and Pantel, Patrick},
  journal={Journal of artificial intelligence research},
  volume={37},
  pages={141--188},
  year={2010}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
  journal={arXiv preprint arXiv:1706.03762},
  year={2017}
}
